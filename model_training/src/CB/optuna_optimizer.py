import os
import yaml
from math import sqrt

import optuna
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor, Pool
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error


class OptunaOptimizer:
    def __init__(self, config, model_type="catboost", n_trials=5):
        self.config = config
        self.model_type = model_type.lower()
        self.n_trials = n_trials

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        train_path = os.path.join(self.config.data_path, "train.csv")
        test_path = os.path.join(self.config.data_path, "test.csv")

        train_data = pd.read_csv(train_path)
        test_data = pd.read_csv(test_path)

        return train_data, test_data

    def prepare_data(self, train_data, test_data, model_type="catboost"):
        """Train/Test ë°ì´í„°ì—ì„œ Featureì™€ Targetì„ ë¶„ë¦¬ (Categorical Features ì œì™¸)"""
        target_column = self.config.data_params["target_column"]
        categorical_features = None

        if model_type == "catboost":
            categorical_features = self.config.data_params["categorical_features"]
            numerical_features = self.config.data_params["numerical_features"]
            features = numerical_features + categorical_features

            X_train = train_data[features]
            y_train = train_data[target_column]
            X_test = test_data[features]
            y_test = test_data[target_column]

        if model_type == "xgboost":
            train_data = train_data.drop([
                "freelancer_id",
                "project_id",
                "Unnamed: 0_x",
                "project_duration",
                "project_priority",
                "project_company",
                "project_category",
                "category_name",
                "project_skills",
                "Unnamed: 0_y",
                "freelancer_skills",
                "skill_temp",
                "freelancer_category",
            ], axis=1)
            test_data = test_data.drop([
                "freelancer_id",
                "project_id",
                "Unnamed: 0_x",
                "project_duration",
                "project_priority",
                "project_company",
                "project_category",
                "category_name",
                "project_skills",
                "Unnamed: 0_y",
                "freelancer_skills",
                "skill_temp",
                "freelancer_category",
            ], axis=1)

            X_train = np.array(train_data.drop(target_column, axis=1))
            y_train = np.array(train_data[target_column])
            X_test = np.array(test_data.drop(target_column, axis=1))
            y_test = np.array(test_data[target_column])

        return X_train, X_test, y_train, y_test, categorical_features

    def objective(self, trial):
        """Optuna ìµœì í™” ëª©í‘œ í•¨ìˆ˜"""

        if self.model_type == "catboost":
            params = {
                "iterations": trial.suggest_int("iterations", 100, 1000),
                "depth": trial.suggest_int("depth", 4, 10),
                "learning_rate": trial.suggest_loguniform("learning_rate", 0.01, 0.3),
                "l2_leaf_reg": trial.suggest_loguniform("l2_leaf_reg", 1e-3, 10),
                "random_seed": 42,
                "verbose": 0,
                "od_type": "Iter",
                "od_wait": 50,
                "task_type": "GPU"
            }
            train_pool = Pool(self.X_train, self.y_train, cat_features=self.categorical_features)
            model = CatBoostRegressor(**params)
            model.fit(train_pool, early_stopping_rounds=50)

        elif self.model_type == "xgboost":
            params = {
                "n_estimators": trial.suggest_int("n_estimators", 100, 1000),
                "max_depth": trial.suggest_int("max_depth", 3, 10),
                "learning_rate": trial.suggest_loguniform("learning_rate", 0.01, 0.3),
                "subsample": trial.suggest_uniform("subsample", 0.5, 1.0),
                "colsample_bytree": trial.suggest_uniform("colsample_bytree", 0.5, 1.0),
                "reg_lambda": trial.suggest_loguniform("reg_lambda", 1e-3, 10),
                "random_state": 42
            }
            model = XGBRegressor(**params)
            model.fit(self.X_train, self.y_train)

        else:
            raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. 'catboost' ë˜ëŠ” 'xgboost'ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

        y_pred_scores = model.predict(self.X_test)

        rmse = sqrt(mean_squared_error(self.y_test, y_pred_scores))

        return rmse

    def run(self):
        """Optuna ì‹¤í–‰"""
        print("ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹œì‘...")
        train_data, test_data = self.load_data()
        self.X_train, self.X_test, self.y_train, self.y_test, self.categorical_features = self.prepare_data(train_data, test_data, model_type=self.model_type.lower())

        print(f"Optunaë¥¼ ì´ìš©í•œ {self.model_type} í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...")
        study = optuna.create_study(direction="minimize")
        study.optimize(self.objective, n_trials=self.n_trials)

        print(f"ğŸ‰ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {study.best_params}")
        self.save_best_params(study.best_params)

    def save_best_params(self, best_params):
        """config.yamlì˜ xgboost/catboost ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸"""
        config_path = "config/config.yaml"

        # ê¸°ì¡´ YAML íŒŒì¼ ë¡œë“œ
        if os.path.exists(config_path):
            with open(config_path, "r") as f:
                config_data = yaml.safe_load(f)
        else:
            config_data = {}

        # catboost_params ì—…ë°ì´íŠ¸
        if f"{self.model_type}_params" not in config_data:
            config_data["catboost_params"] = {}

        config_data[f"{self.model_type}_params"].update(best_params)

        # ì—…ë°ì´íŠ¸ëœ ì„¤ì • ì €ì¥
        with open(config_path, "w") as f:
            yaml.dump(config_data, f, default_flow_style=False, sort_keys=False)

        print(f"âœ”ï¸ {self.model_type}_params ì—…ë°ì´íŠ¸ ì™„ë£Œ: {config_path}")