import os
import pandas as pd
import json

from sqlalchemy import text
from dotenv import load_dotenv
from langchain_upstage import UpstageEmbeddings
from typing import Tuple, List, Dict
from sklearn.preprocessing import MultiLabelBinarizer

from api.db import SessionLocal
from src.utils import check_path

import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

def load_data(data_path: str):
    """
    DBì—ì„œ ë°ì´í„° ë¡œë“œ í›„ CSV íŒŒì¼ë¡œ ì €ì¥

    Args:
        data_path (str): ë°ì´í„° ì €ì¥ ê²½ë¡œ
    """
    db = SessionLocal()

    try:
        sql_project_info = """
            SELECT  P.PROJECT_ID AS project_id,
                    P.DURATION AS duration,
                    ROUND(P.BUDGET / P.DURATION, 0) AS budget,
                    P.PRIORITY AS priority,
                    P.COMPANY_ID AS company_id,
                    (SELECT JSON_ARRAYAGG(PC.CATEGORY_ID)
                     FROM PROJECT PC
                     WHERE PC.PROJECT_ID = P.PROJECT_ID) AS category_id,
                    (SELECT JSON_ARRAYAGG(PS.SKILL_ID)
                     FROM PROJECT_SKILL PS
                     WHERE PS.PROJECT_ID = P.PROJECT_ID) AS skill_id,
                    P.FREELANCER_ID AS freelancer_id
            FROM    PROJECT P
            JOIN    CATEGORY C ON P.CATEGORY_ID = C.CATEGORY_ID
            WHERE   P.STATUS IN (1, 2)
            """

        sql_project_content = """
            SELECT PROJECT_ID AS project_id,
                   DBMS_LOB.SUBSTR(PROJECT_CONTENT, 32767, 1) AS project_content
            FROM PROJECT
            WHERE STATUS IN (1, 2)
            """

        sql_freelancer = """
            SELECT  F.FREELANCER_ID AS freelancer_id,
                    F.WORK_EXP AS work_exp,
                    ROUND(F.PRICE / 365, 0) AS price,
                    (SELECT JSON_ARRAYAGG(FS.SKILL_ID) AS SKILL_ID
                     FROM FREELANCER_SKILL FS
                     WHERE FS.FREELANCER_ID = F.FREELANCER_ID) AS skill_id,
                    (SELECT JSON_ARRAYAGG(FS.SKILL_SCORE) AS SKILL_TEMP
                     FROM FREELANCER_SKILL FS
                     WHERE FS.FREELANCER_ID = F.FREELANCER_ID) AS skill_temp,
                    (SELECT JSON_ARRAYAGG(FC.CATEGORY_ID)
                     FROM FREELANCER_CATEGORY FC
                     WHERE FC.FREELANCER_ID = F.FREELANCER_ID) AS category_id
            FROM    FREELANCER F
            """

        sql_inter = """
            SELECT  PROJECT_ID AS project_id,
                    FREELANCER_ID AS freelancer_id,
                    MATCHING_SCORE AS matching_score
            FROM (
                SELECT  PROJECT_ID,
                        FREELANCER_ID,
                        MATCHING_SCORE / 100 AS MATCHING_SCORE,
                        ROW_NUMBER() OVER (PARTITION BY PROJECT_ID ORDER BY MATCHING_SCORE DESC) AS RANKING
                FROM    PROJECT_RANKING
            )
            ORDER BY PROJECT_ID, RANKING
            """

        sql_inter_implicit = """
            SELECT  PROJECT_ID AS project_id,
                    FREELANCER_ID AS freelancer_id,
                    (CASE WHEN RANKING <= 10 THEN 1
                          ELSE 0
                    END) AS matching_score
            FROM (
                SELECT  PROJECT_ID,
                        FREELANCER_ID,
                        ROW_NUMBER() OVER (PARTITION BY PROJECT_ID ORDER BY MATCHING_SCORE DESC) AS RANKING
                FROM    PROJECT_RANKING
            )
            ORDER BY PROJECT_ID, RANKING
            """

        project_info_df = pd.read_sql(text(sql_project_info), db.bind)
        project_content_df = pd.read_sql(text(sql_project_content), db.bind)
        project_df = project_info_df.merge(project_content_df, on="project_id", how="left")
        freelancer_df = pd.read_sql(text(sql_freelancer), db.bind)
        inter_df = pd.read_sql(text(sql_inter), db.bind)
        inter_implicit_df = pd.read_sql(text(sql_inter_implicit), db.bind)

        check_path(data_path)
        project_df.to_csv(os.path.join(data_path, "project.csv"), index=False)
        freelancer_df.to_csv(os.path.join(data_path, "freelancer.csv"), index=False)
        inter_df.to_csv(os.path.join(data_path, "inter.csv"), index=False)
        inter_implicit_df.to_csv(os.path.join(data_path, "inter_implicit.csv"), index=False)

    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    finally:
        db.close()


def preprocess_data(data_path: str, n_components: int):
    """
    ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜

    Args:
        data_path (str): ë°ì´í„° ì €ì¥ ê²½ë¡œ
        n_components (int): ì£¼ì„±ë¶„ ê°œìˆ˜
    """
    project_df = pd.read_csv(os.path.join(data_path, "project.csv"))
    freelancer_df = pd.read_csv(os.path.join(data_path, "freelancer.csv"))
    project_df = project_df.head(5)
    freelancer_df = freelancer_df.head(5)

    print("ğŸ“ preprocessing project ==============================")
    project_df = Preprocessing.text_embedding(project_df, "project_content", n_components)

    print("ğŸ“ preprocessing freelancer ===========================")

    # project_df.to_csv(os.path.join(data_path, "project_test.csv"), index=False)
    # freelancer_df.to_csv(os.path.join(data_path, "freelancer_test.csv"), index=False)


class Preprocessing:
    def text_embedding(df: pd.DataFrame, col_name: str, n_components: int) -> pd.DataFrame:
        """
        í…ìŠ¤íŠ¸ ì„ë² ë”© í•¨ìˆ˜ (Upstage Embeddings ì‚¬ìš©)

        Args
            df (pd.DataFrame): ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ ìˆëŠ” ë°ì´í„°í”„ë ˆì„
            col_name (str): ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…
            n_components (int): ì£¼ì„±ë¶„ ê°œìˆ˜

        Returns:
            pd.DataFrame: ì„ë² ë”©ëœ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
        """
        load_dotenv()
        UPSTAGE_TOKEN = os.getenv("UPSTAGE_TOKEN")

        embeddings = UpstageEmbeddings(
            api_key=UPSTAGE_TOKEN,
            model="embedding-passage"
        )

        emb_results = embeddings.embed_documents(df[col_name].tolist())
        df[col_name] = emb_results

        # íŠ¹ì • ì»¬ëŸ¼ì˜ ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜í•˜ê³ , ê° ë°°ì—´ì„ reshapeí•˜ì—¬ 1í–‰ nì—´ í˜•íƒœë¡œ ë³€í™˜
        df_col_name = df[col_name].apply(lambda x: np.array(x).reshape(1,-1))

        # ë³€í™˜ëœ ë°°ì—´ë“¤ì„ í•˜ë‚˜ì˜ numpy ë°°ì—´ë¡œ í•©ì¹¨ (axis=0ì„ ê¸°ì¤€ìœ¼ë¡œ í•©ì¹¨)
        df_col_name = np.concatenate(df_col_name.values, axis=0)

        # numpy ë°°ì—´ì„ ë‹¤ì‹œ pandas DataFrameìœ¼ë¡œ ë³€í™˜
        df_col_name = pd.DataFrame(df_col_name)

        # StandardScalerë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ í‘œì¤€í™” (í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ì¡°ì •)
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(df_col_name)

        #  PCA ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        np.random.seed(42)
        pca = PCA(n_components=n_components, random_state=42)
        X_pca = pca.fit_transform(X_scaled)

        # PCA ê²°ê³¼ë¥¼ pandas DataFrameìœ¼ë¡œ ë³€í™˜
        x_pca_df = pd.DataFrame(X_pca)

        # ìƒˆë¡œìš´ ì»¬ëŸ¼ ì´ë¦„ ìƒì„± í›„ ë³€ê²½ (ì˜ˆ: project_content_0, project_content_1, ...)
        new_columns = [f"project_content_{i}" for i in range(len(x_pca_df.columns))]
        x_pca_df.columns = new_columns

        # ì›ë³¸ DataFrameì— PCA ê²°ê³¼ë¥¼ ë³‘í•© (ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©)
        df = pd.merge(df, x_pca_df, left_index=True, right_index=True)

        # ì›ë˜ì˜ "project_content" ì»¬ëŸ¼ì„ ì‚­ì œ
        df = df.drop("project_content", axis=1)

        return df

    def parse_column(value: str) -> Tuple[List[str], Dict[str, float]]:
        """
        JSON í˜•íƒœ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë¬¸ìì—´ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜.

        Args:
            value(str) : JSON ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´

        Returns:
            list : ë³€í™˜ëœ ë¦¬ìŠ¤íŠ¸
            dict : ê°€ì¤‘ì¹˜ ë”•ì…”ë„ˆë¦¬ (í”„ë¦¬ëœì„œ skill_idë§Œ í•´ë‹¹, ì—†ìœ¼ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬)
        """
        parsed_list = []
        weights = {}

        try:
            parsed = json.loads(value.replace("'", '"')) if "{" in value else eval(value)

            if isinstance(parsed, list):
                if all(isinstance(item, dict) for item in parsed):
                    for skill in parsed:
                        parsed_list.append(skill["skill_id"])
                        weights[skill["skill_id"]] = skill.get("skill_score", 1)
                else:
                    parsed_list = parsed
        except (json.JSONDecodeError, SyntaxError, TypeError):
            pass

        return parsed_list, weights

    def multi_hot_encoding(
            df: pd.DataFrame,
            label_col: str,
            pivot_col: str,
            weight_col: str = None
    ) -> pd.DataFrame:
        """
        í”„ë¡œì íŠ¸ ë° í”„ë¦¬ëœì„œì˜ ìŠ¤í‚¬ì„ ë©€í‹°-í•« ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜
        (í”„ë¦¬ëœì„œì˜ ê²½ìš° ìŠ¤í‚¬ ì˜¨ë„ë¥¼ ì ìš©)

        Args:
            df (pd.DataFrame): pivot_colê³¼ label_colì„ í¬í•¨í•˜ëŠ” ë°ì´í„°í”„ë ˆì„
            label_col (str): ë©€í‹°í•« ì¸ì½”ë”©í•  ìŠ¤í‚¬ ì»¬ëŸ¼ëª…
            pivot_col (str): ê·¸ë£¹í™”í•  ê¸°ì¤€ì´ ë˜ëŠ” ì»¬ëŸ¼ëª… (project_id ë˜ëŠ” freelancer_id)
            weight_col (str, optional): ìŠ¤í‚¬ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•  ê²½ìš° ì œê³µí•  ì»¬ëŸ¼ëª… (í”„ë¦¬ëœì„œë§Œ í•´ë‹¹)

        Returns:
            pd.DataFrame: ë©€í‹°í•« ì¸ì½”ë”©(ë° ê°€ì¤‘ì¹˜ ì ìš©)ì´ ì™„ë£Œëœ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
        """

        # ìŠ¤í‚¬ ì»¬ëŸ¼ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜
        df[["parsed_values", "parsed_weights"]] = df[label_col].apply(
            lambda x: pd.Series(Preprocessing.parse_column(str(x)))
        )

        # pivot_colë³„ "parsed_values"ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ê¸°
        grouped_df = df.groupby(pivot_col)["parsed_values"].sum().reset_index()

        # MultiLabelBinarizerë¥¼ ì‚¬ìš©í•˜ì—¬ ë©€í‹° í•« ì¸ì½”ë”© ìˆ˜í–‰
        mlb = MultiLabelBinarizer()
        multi_hot_encoded = mlb.fit_transform(grouped_df["parsed_values"])

        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        multi_hot_df = pd.DataFrame(multi_hot_encoded, columns=mlb.classes_)
        multi_hot_df.insert(0, pivot_col, grouped_df[pivot_col])

        # ê°€ì¤‘ì¹˜ ì ìš© (í”„ë¦¬ëœì„œ ìŠ¤í‚¬ ì˜¨ë„ ì ìš©)
        if weight_col and "parsed_weights" in df:
            weight_map = {
                row[pivot_col]: row["parsed_weights"] for _, row in df.iterrows()
            }
            for skill in mlb.classes_:
                if skill in multi_hot_df.columns:
                    multi_hot_df[skill] = multi_hot_df[pivot_col].map(
                        lambda x: weight_map.get(x, {}).get(skill, 1)
                    ) * multi_hot_df[skill]

        return multi_hot_df
